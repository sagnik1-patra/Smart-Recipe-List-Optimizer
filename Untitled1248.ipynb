{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91a921b8-a4f7-4564-8f1a-23a70576f3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading recipes...\n",
      "[INFO] Fitting TF-IDF (first time in this session)...\n",
      "\n",
      "[STEP 1] Retrieve top recipes for the meal plan...\n",
      "    id                                                     name    score\n",
      "106830                        special fried rice  rachael ray s 0.249239\n",
      "143501                                             paneer tikka 0.246493\n",
      "253298                      quick fix layered chicken casserole 0.208443\n",
      "351616                      lentil soup w spicy tomatoes   rice 0.206918\n",
      "137200                                  fried rice chicken soup 0.203894\n",
      "101505                                    just another stir fry 0.194482\n",
      "103894                    dal and rice with spicy fried cabbage 0.193244\n",
      "417193             healthiest stir fry with veggies and chicken 0.186683\n",
      "162093                                  chicken and salad pitas 0.186408\n",
      "448061 grilled lime chicken  sandwich  salad  wrap or main dish 0.185574\n",
      "\n",
      "[STEP 2] Build merged shopping list...\n",
      "                  name  qty unit                                examples\n",
      "             asparagus None                                    asparagus\n",
      "          baby carrots None                                 baby carrots\n",
      "          black pepper None                                 black pepper\n",
      "                butter None                                       butter\n",
      "      button mushrooms None                             button mushrooms\n",
      "                carrot None                               carrot; carrot\n",
      "               carrots None                                      carrots\n",
      "           chat masala None                                  chat masala\n",
      "        chicken breast None                               chicken breast\n",
      " chicken breast halves None      boneless skinless chicken breast halves\n",
      "chicken breast tenders None                       chicken breast tenders\n",
      "         chicken broth None                 chicken broth; chicken broth\n",
      "        chicken thighs None             boneless skinless chicken thighs\n",
      "          chili powder None                                 chili powder\n",
      "              cinnamon None                                     cinnamon\n",
      "                cloves None                                ground cloves\n",
      "     cooked brown rice None                            cooked brown rice\n",
      "        cooked chicken None               cooked chicken; cooked chicken\n",
      "             coriander None                                    coriander\n",
      "      coriander leaves None                             coriander leaves\n",
      "\n",
      "[STEP 3] (Optional) Simulate prices & optimize cart...\n",
      "Single-store best: Blinkit → ₹198.69 (simulated). Breakdown: {'BigBasket': 199.0, 'Blinkit': 198.69, 'Walmart': 199.25}\n",
      "[Multi-store] Skipped: PuLP not installed; skipping multi-store optimization.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Prediction / Inference pipeline:\n",
    "# - Input: user meal plan text or list of dishes\n",
    "# - Output: top-K matching recipes, merged shopping list\n",
    "# - Optional: price simulation & cost optimization (single-store vs multi-store)\n",
    "\n",
    "# If needed once:\n",
    "# !pip install pandas numpy scikit-learn tqdm pulp\n",
    "\n",
    "import re, ast, math, random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "try:\n",
    "    import pulp  # for LP optimization\n",
    "    HAS_PULP = True\n",
    "except Exception:\n",
    "    HAS_PULP = False\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "BASE_DIR    = r\"C:\\Users\\sagni\\Downloads\\Smart Grocery List Optimizer\"\n",
    "ARCHIVE     = str(Path(BASE_DIR) / \"archive\")\n",
    "RAW_RECIPES = str(Path(ARCHIVE) / \"RAW_recipes.csv\")    # Food.com raw recipes\n",
    "TOP_K       = 10                                        # how many recipes to return\n",
    "SEED        = 7\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def clean_text(s: str) -> str:\n",
    "    if s is None or (isinstance(s,float) and math.isnan(s)): return \"\"\n",
    "    s = str(s).lower().strip()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "def row_text(row) -> str:\n",
    "    # combine name + ingredients + steps for retrieval\n",
    "    name = clean_text(row.get(\"name\", \"\"))\n",
    "    ings = clean_text(row.get(\"ingredients\", \"\"))\n",
    "    steps = clean_text(row.get(\"steps\", \"\"))\n",
    "    return f\"{name} {ings} {steps}\"\n",
    "\n",
    "def safe_list_parse(x):\n",
    "    \"\"\"Food.com fields often look like \"['onions', 'salt']\". Parse safely to list.\"\"\"\n",
    "    if isinstance(x, list): return x\n",
    "    s = str(x)\n",
    "    try:\n",
    "        obj = ast.literal_eval(s)\n",
    "        if isinstance(obj, list):\n",
    "            return [str(i) for i in obj]\n",
    "        return [s]\n",
    "    except Exception:\n",
    "        # fallback: split on commas\n",
    "        s = s.strip(\"[]\")\n",
    "        parts = [p.strip().strip(\"'\").strip('\"') for p in s.split(\",\") if p.strip()]\n",
    "        return parts if parts else [s]\n",
    "\n",
    "# minimal units and normalization\n",
    "UNIT_ALIASES = {\n",
    "    \"g\": [\"g\",\"gram\",\"grams\"],\n",
    "    \"kg\": [\"kg\",\"kilogram\",\"kilograms\"],\n",
    "    \"ml\": [\"ml\",\"milliliter\",\"milliliters\"],\n",
    "    \"l\": [\"l\",\"liter\",\"liters\"],\n",
    "    \"tsp\": [\"tsp\",\"teaspoon\",\"teaspoons\"],\n",
    "    \"tbsp\": [\"tbsp\",\"tablespoon\",\"tablespoons\"],\n",
    "    \"cup\": [\"cup\",\"cups\"],\n",
    "    \"piece\": [\"piece\",\"pieces\",\"pc\",\"pcs\"],\n",
    "}\n",
    "UNIT_LOOKUP = {alias:u for u, aliases in UNIT_ALIASES.items() for alias in aliases}\n",
    "\n",
    "def extract_qty_unit(item: str):\n",
    "    \"\"\"\n",
    "    Very lightweight quantity/unit extractor.\n",
    "    Examples:\n",
    "        \"2 cups rice\" -> qty=2.0, unit=cup, name=\"rice\"\n",
    "        \"200 g chicken breast\" -> 200, g, \"chicken breast\"\n",
    "        \"1 onion\" -> 1, piece, \"onion\"\n",
    "        \"salt to taste\" -> None, None, \"salt\"\n",
    "    \"\"\"\n",
    "    s = clean_text(item)\n",
    "    # try number at start\n",
    "    m = re.match(r\"^(\\d+(?:\\.\\d+)?)(?:\\s*([a-zA-Z]+))?\\s+(.*)$\", s)\n",
    "    if m:\n",
    "        qty = float(m.group(1))\n",
    "        raw_unit = m.group(2) or \"\"\n",
    "        unit = UNIT_LOOKUP.get(raw_unit.lower(), None) if raw_unit else None\n",
    "        name = m.group(3).strip()\n",
    "        # if unit missing but name starts with unit word\n",
    "        if not unit:\n",
    "            m2 = re.match(r\"^([a-zA-Z]+)\\s+(.*)$\", name)\n",
    "            if m2 and UNIT_LOOKUP.get(m2.group(1).lower(), None):\n",
    "                unit = UNIT_LOOKUP[m2.group(1).lower()]\n",
    "                name = m2.group(2).strip()\n",
    "        if not unit and qty.is_integer():  # default to piece for integers\n",
    "            unit = \"piece\"\n",
    "        return qty, unit, name\n",
    "    # if no leading number: assume name only\n",
    "    return None, None, s\n",
    "\n",
    "def merge_ingredient_line(item: str):\n",
    "    \"\"\"Return canonical (name, qty, unit).\"\"\"\n",
    "    qty, unit, name = extract_qty_unit(item)\n",
    "    # strip descriptors from name\n",
    "    name = re.sub(r\"\\b(chopped|diced|minced|sliced|fresh|ground|to taste|large|small|medium|boneless|skinless)\\b\", \"\", name)\n",
    "    name = re.sub(r\"[^a-z0-9\\s\\-]\", \"\", name).strip()\n",
    "    name = re.sub(r\"\\s+\", \" \", name)\n",
    "    if not name:\n",
    "        name = item\n",
    "    return name, qty, unit\n",
    "\n",
    "def merge_ingredients(list_of_lists):\n",
    "    \"\"\"\n",
    "    Input: list of ingredient lists (strings)\n",
    "    Output: dict {name: {\"unit\": unit or None, \"qty\": total_qty (can be None), \"lines\": [raw]}}\n",
    "    - We sum quantities when unit matches; if not, we keep separate entries by (name, unit).\n",
    "    \"\"\"\n",
    "    merged = {}\n",
    "    for ing_list in list_of_lists:\n",
    "        for raw in ing_list:\n",
    "            name, qty, unit = merge_ingredient_line(raw)\n",
    "            key = (name, unit or \"unitless\")\n",
    "            if key not in merged:\n",
    "                merged[key] = {\"name\": name, \"unit\": unit, \"qty\": 0.0 if qty is not None else None, \"lines\": [raw]}\n",
    "            else:\n",
    "                merged[key][\"lines\"].append(raw)\n",
    "                if qty is not None:\n",
    "                    if merged[key][\"qty\"] is None:\n",
    "                        merged[key][\"qty\"] = qty\n",
    "                    else:\n",
    "                        merged[key][\"qty\"] += qty\n",
    "    # convert to list for display\n",
    "    out = []\n",
    "    for (name, unit), data in merged.items():\n",
    "        out.append({\n",
    "            \"name\": data[\"name\"],\n",
    "            \"qty\": round(data[\"qty\"], 2) if isinstance(data[\"qty\"], (int,float)) else None,\n",
    "            \"unit\": data[\"unit\"] if data[\"unit\"] else \"\",\n",
    "            \"examples\": \"; \".join(data[\"lines\"][:3])\n",
    "        })\n",
    "    # sort alphabetically\n",
    "    out = sorted(out, key=lambda x: x[\"name\"])\n",
    "    return out\n",
    "\n",
    "# =========================\n",
    "# Load recipes and build vectorizer (fit once; reuse for predictions)\n",
    "# =========================\n",
    "print(\"[INFO] Loading recipes...\")\n",
    "df = pd.read_csv(RAW_RECIPES)\n",
    "keep = [c for c in [\"id\",\"name\",\"ingredients\",\"steps\"] if c in df.columns]\n",
    "df = df[keep].copy()\n",
    "if \"ingredients\" not in df.columns: df[\"ingredients\"] = \"\"\n",
    "if \"steps\" not in df.columns: df[\"steps\"] = \"\"\n",
    "\n",
    "df[\"doc_text\"] = (df[\"name\"].astype(str) + \" \" + df[\"ingredients\"].astype(str) + \" \" + df[\"steps\"].astype(str)).map(clean_text)\n",
    "\n",
    "print(\"[INFO] Fitting TF-IDF (first time in this session)...\")\n",
    "vec = TfidfVectorizer(max_features=50000, ngram_range=(1,2), stop_words=\"english\")\n",
    "X  = vec.fit_transform(df[\"doc_text\"].tolist())\n",
    "\n",
    "# =========================\n",
    "# Prediction functions\n",
    "# =========================\n",
    "def score_recipes(meal_plan_text: str, top_k: int = TOP_K) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns top_k recipes most similar to the user's meal plan text.\n",
    "    \"\"\"\n",
    "    q = vec.transform([clean_text(meal_plan_text)])\n",
    "    sims = cosine_similarity(X, q).ravel()\n",
    "    out = df[[\"id\",\"name\",\"ingredients\"]].copy()\n",
    "    out[\"score\"] = sims\n",
    "    out = out.sort_values(\"score\", ascending=False).head(top_k).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "def build_shopping_list(top_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    From selected recipes, parse and merge ingredients.\n",
    "    \"\"\"\n",
    "    all_ing_lists = []\n",
    "    for _, row in top_df.iterrows():\n",
    "        ings = safe_list_parse(row.get(\"ingredients\", \"[]\"))\n",
    "        all_ing_lists.append(ings)\n",
    "    merged = merge_ingredients(all_ing_lists)\n",
    "    shop = pd.DataFrame(merged, columns=[\"name\",\"qty\",\"unit\",\"examples\"])\n",
    "    return shop\n",
    "\n",
    "# =========================\n",
    "# (Optional) Price simulation + cost optimization\n",
    "# =========================\n",
    "def simulate_store_prices(items_df: pd.DataFrame, stores=(\"BigBasket\",\"Blinkit\",\"Walmart\"), seed=SEED):\n",
    "    \"\"\"\n",
    "    Create a fake price table per item per store: name -> {store: unit_price}\n",
    "    Real integration would fetch actual SKU prices & map units.\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    prices = {}\n",
    "    for _, row in items_df.iterrows():\n",
    "        base = rng.uniform(0.5, 5.0)  # base unit price\n",
    "        prices[row[\"name\"]] = {}\n",
    "        for s in stores:\n",
    "            # add small noise per store\n",
    "            prices[row[\"name\"]][s] = round(base * rng.uniform(0.85, 1.20), 2)\n",
    "    return prices\n",
    "\n",
    "def optimize_cart_single_store(items_df: pd.DataFrame, store_prices: dict):\n",
    "    \"\"\"\n",
    "    Choose one store that minimizes total cost.\n",
    "    Returns (best_store, total_cost).\n",
    "    \"\"\"\n",
    "    totals = {}\n",
    "    for store in next(iter(store_prices.values())).keys():\n",
    "        total = 0.0\n",
    "        for _, row in items_df.iterrows():\n",
    "            qty = row[\"qty\"] if row[\"qty\"] and row[\"qty\"]>0 else 1.0\n",
    "            price = store_prices.get(row[\"name\"], {}).get(store, 9999)\n",
    "            total += qty * price\n",
    "        totals[store] = round(total, 2)\n",
    "    best_store = min(totals, key=totals.get)\n",
    "    return best_store, totals[best_store], totals\n",
    "\n",
    "def optimize_cart_multi_store(items_df: pd.DataFrame, store_prices: dict):\n",
    "    \"\"\"\n",
    "    Linear program: for each item, select exactly one store to buy from, minimizing total cost.\n",
    "    \"\"\"\n",
    "    if not HAS_PULP:\n",
    "        return None, None, \"PuLP not installed; skipping multi-store optimization.\"\n",
    "\n",
    "    prob = pulp.LpProblem(\"GroceryMinCost\", pulp.LpMinimize)\n",
    "\n",
    "    stores = list(next(iter(store_prices.values())).keys())\n",
    "    # Decision vars x[i, s] in {0,1}\n",
    "    x = {}\n",
    "    for i, row in items_df.iterrows():\n",
    "        item = row[\"name\"]\n",
    "        for s in stores:\n",
    "            x[(i,s)] = pulp.LpVariable(f\"x_{i}_{s}\", cat=\"Binary\")\n",
    "\n",
    "    # Objective\n",
    "    obj = 0\n",
    "    for i, row in items_df.iterrows():\n",
    "        qty = row[\"qty\"] if row[\"qty\"] and row[\"qty\"]>0 else 1.0\n",
    "        for s in stores:\n",
    "            price = store_prices.get(row[\"name\"], {}).get(s, 9999)\n",
    "            obj += qty * price * x[(i,s)]\n",
    "    prob += obj\n",
    "\n",
    "    # Constraints: each item picked exactly once\n",
    "    for i, _ in items_df.iterrows():\n",
    "        prob += pulp.lpSum([x[(i,s)] for s in stores]) == 1\n",
    "\n",
    "    prob.solve(pulp.PULP_CBC_CMD(msg=False))\n",
    "\n",
    "    selection = []\n",
    "    total = 0.0\n",
    "    for i, row in items_df.iterrows():\n",
    "        item = row[\"name\"]\n",
    "        qty = row[\"qty\"] if row[\"qty\"] and row[\"qty\"]>0 else 1.0\n",
    "        chosen = None; price = None\n",
    "        for s in stores:\n",
    "            if pulp.value(x[(i,s)]) > 0.5:\n",
    "                chosen = s\n",
    "                price = store_prices[item][s]\n",
    "                break\n",
    "        selection.append({\"name\": item, \"store\": chosen, \"unit_price\": price, \"qty\": qty, \"cost\": round(qty*price,2)})\n",
    "        total += qty * price\n",
    "    sel_df = pd.DataFrame(selection)\n",
    "    return sel_df, round(total,2), None\n",
    "\n",
    "# =========================\n",
    "# EXAMPLE USAGE\n",
    "# =========================\n",
    "meal_plan = \"\"\"\n",
    "chicken curry, vegetable fried rice, dal tadka, grilled chicken salad, lemon rice,\n",
    "quick stir-fry veggies, lentil soup, paneer wraps\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n[STEP 1] Retrieve top recipes for the meal plan...\")\n",
    "top_df = score_recipes(meal_plan, top_k=TOP_K)\n",
    "display_cols = [\"id\",\"name\",\"score\"]\n",
    "print(top_df[display_cols].to_string(index=False))\n",
    "\n",
    "print(\"\\n[STEP 2] Build merged shopping list...\")\n",
    "shopping_df = build_shopping_list(top_df)\n",
    "print(shopping_df.head(20).to_string(index=False))\n",
    "\n",
    "print(\"\\n[STEP 3] (Optional) Simulate prices & optimize cart...\")\n",
    "price_table = simulate_store_prices(shopping_df)\n",
    "best_store, single_cost, all_totals = optimize_cart_single_store(shopping_df, price_table)\n",
    "print(f\"Single-store best: {best_store} → ₹{single_cost:.2f} (simulated). Breakdown: {all_totals}\")\n",
    "\n",
    "multi_sel, multi_cost, msg = optimize_cart_multi_store(shopping_df, price_table)\n",
    "if msg:\n",
    "    print(\"[Multi-store] Skipped:\", msg)\n",
    "else:\n",
    "    print(f\"[Multi-store] Optimal split cost → ₹{multi_cost:.2f} (simulated)\")\n",
    "    print(multi_sel.head(20).to_string(index=False))\n",
    "\n",
    "# Hints for integrating into an API/UI:\n",
    "# - Wrap score_recipes() + build_shopping_list() in a FastAPI endpoint: POST /plan -> returns top recipes + shopping list.\n",
    "# - Replace simulate_store_prices() with real price lookups (BigBasket/Blinkit/Walmart) and proper unit mapping.\n",
    "# - Persist results as JSON for the frontend to render.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be94cd5-6112-4b6b-84a8-5633df39383b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
